indsTrain <- setdiff(1:nrow(transfSpam),indsTest)
transfSpamTest <- transfSpam[indsTest,]
transfSpamTrain <- transfSpam[indsTrain,]
fit = glm(type~our+over+remove+internet+free+business+credit+your+font+num000+money+hp +
hpl+george+data+num1999+meeting+project+re+edu+
conference+charSemicolon+charExclamation+charDollar+
capitalAve+capitalLong+capitalTotal,
family = binomial,data = transfSpamTrain)
pred_prob = predict(fit,transfSpamTest, type="response")
pred = rep("nonspam", dim(transfSpamTest)[1])
pred[pred_prob > .5] = "spam"
#confusion matrix
conf1 = table(pred, transfSpamTest$type)
pred_prob = predict.gamsel(cvmodel$gamsel.fit, transfSpamTest[,-58], index=49, type="response")
pred = rep("nonspam", dim(transfSpamTest)[1])
pred[pred_prob> .5] = "spam"
#confusion matrix
conf2 = table(pred, transfSpamTest$type)
error1 = conf1[2,1]/(conf1[1,1]+conf1[2,1])
error2 = conf2[2,1]/(conf2[1,1]+conf2[2,1])
list1 = append(list1,error1)
list2 = append(list2,error2)
mis1 = (conf1[1,2]+conf1[2,1])/1000
mis2 = (conf2[1,2]+conf2[2,1])/1000
list3 = append(list3,mis1)
list4 = append(list4,mis2)
}
#(g)
list1 = c()
list2 = c()
list3 = c()
list4 = c()
for (i in 1:100){
transfSpam <- spam
transfSpam[,-58] <- log(transfSpam[,-58] + 1)
nTest <- 1000
indsTest <- sample(1:nrow(transfSpam),nTest,
replace = FALSE)
indsTrain <- setdiff(1:nrow(transfSpam),indsTest)
transfSpamTest <- transfSpam[indsTest,]
transfSpamTrain <- transfSpam[indsTrain,]
fit = glm(type~our+over+remove+internet+free+business+credit+your+font+num000+money+hp +
hpl+george+data+num1999+meeting+project+re+edu+
conference+charSemicolon+charExclamation+charDollar+
capitalAve+capitalLong+capitalTotal,
family = binomial,data = transfSpamTrain)
pred_prob = predict(fit,transfSpamTest, type="response")
pred = rep("nonspam", dim(transfSpamTest)[1])
pred[pred_prob > .5] = "spam"
#confusion matrix
conf1 = table(pred, transfSpamTest$type)
pred_prob = predict.gamsel(cvmodel$gamsel.fit, transfSpamTest[,-58], index=49, type="response")
pred = rep("nonspam", dim(transfSpamTest)[1])
pred[pred_prob> .5] = "spam"
#confusion matrix
conf2 = table(pred, transfSpamTest$type)
error1 = conf1[2,1]/(conf1[1,1]+conf1[2,1])
error2 = conf2[2,1]/(conf2[1,1]+conf2[2,1])
list1 = append(list1,error1)
list2 = append(list2,error2)
mis1 = (conf1[1,2]+conf1[2,1])/1000
mis2 = (conf2[1,2]+conf2[2,1])/1000
list3 = append(list3,mis1)
list4 = append(list4,mis2)
}
boxplot(list1,list2,names=c('GLM','gamsel'),main = 'Misclassification of Nonspam Messages')
boxplot(list3,list4,names=c('GLM','gamsel'),main = 'Misclassification')
list1 = c()
list2 = c()
list3 = c()
list4 = c()
for (i in 1:10){
transfSpam <- spam
transfSpam[,-58] <- log(transfSpam[,-58] + 1)
nTest <- 1000
indsTest <- sample(1:nrow(transfSpam),nTest,
replace = FALSE)
indsTrain <- setdiff(1:nrow(transfSpam),indsTest)
transfSpamTest <- transfSpam[indsTest,]
transfSpamTrain <- transfSpam[indsTrain,]
fit = glm(type~our+over+remove+internet+free+business+credit+your+font+num000+money+hp +
hpl+george+data+num1999+meeting+project+re+edu+
conference+charSemicolon+charExclamation+charDollar+
capitalAve+capitalLong+capitalTotal,
family = binomial,data = transfSpamTrain)
pred_prob = predict(fit,transfSpamTest, type="response")
pred = rep("nonspam", dim(transfSpamTest)[1])
pred[pred_prob > .5] = "spam"
#confusion matrix
conf1 = table(pred, transfSpamTest$type)
pred_prob = predict.gamsel(cvmodel$gamsel.fit, transfSpamTest[,-58], index=49, type="response")
pred = rep("nonspam", dim(transfSpamTest)[1])
pred[pred_prob> .5] = "spam"
#confusion matrix
conf2 = table(pred, transfSpamTest$type)
error1 = conf1[2,1]/(conf1[1,1]+conf1[2,1])
error2 = conf2[2,1]/(conf2[1,1]+conf2[2,1])
list1 = append(list1,error1)
list2 = append(list2,error2)
mis1 = (conf1[1,2]+conf1[2,1])/1000
mis2 = (conf2[1,2]+conf2[2,1])/1000
list3 = append(list3,mis1)
list4 = append(list4,mis2)
}
boxplot(list1,list2,names=c('GLM','gamsel'),main = 'Misclassification of Nonspam Messages')
boxplot(list3,list4,names=c('GLM','gamsel'),main = 'Misclassification')
par(mfrow=c(2,1))
boxplot(list1,list2,names=c('GLM','gamsel'),main = 'Misclassification of Nonspam Messages')
boxplot(list3,list4,names=c('GLM','gamsel'),main = 'Misclassification')
par(mfrow=c(1,2))
boxplot(list1,list2,names=c('GLM','gamsel'),main = 'Misclassification of Nonspam Messages')
boxplot(list3,list4,names=c('GLM','gamsel'),main = 'Misclassification')
library('astsa')
install.packages('astsa')
##2.2
library('astsa')
##2.2
# Add P(t-4) to regression
temp  = tempr-mean(tempr)  # center temperature
temp2 = temp^2             # square it
trend = time(cmort)        # time
part_lag4 = lag(part, 4)
part_lag4
lag(part,-4)
temp  = tempr-mean(tempr)  # center temperature
temp2 = temp^2             # square it
trend = time(cmort)        # time
part_lag4 = lag(part, 4)
data_set = ts.intersect(cmort, temp, temp2, trend, part, part_lag4, dframe = TRUE)
fit = lm(cmort~ trend + temp + temp2 + part + part_lag4, data = data_set, na.action=NULL)
summary(fit)
library('astsa')
##2.2
# Add P(t-4) to regression
temp  = tempr-mean(tempr)  # center temperature
temp2 = temp^2             # square it
trend = time(cmort)        # time
part_lag4 = lag(part, -4)
data_set = ts.intersect(cmort, temp, temp2, trend, part, part_lag4, dframe = TRUE)
fit = lm(cmort~ trend + temp + temp2 + part + part_lag4, data = data_set, na.action=NULL)
summary(fit)
library('astsa')
##2.2
# Add P(t-4) to regression
temp  = tempr-mean(tempr)  # center temperature
temp2 = temp^2             # square it
trend = time(cmort)        # time
part_lag4 = lag(part, -4)
data_set = ts.intersect(cmort, temp, temp2, trend, part, part_lag4, dframe = TRUE)
fit = lm(cmort~ trend + temp + temp2 + part + part_lag4, data = data_set, na.action=NULL)
summary(fit)
library('astsa')
##2.2
# Add P(t-4) to regression
temp  = tempr-mean(tempr)  # center temperature
temp2 = temp^2             # square it
trend = time(cmort)        # time
part_lag4 = lag(part, 44)
data_set = ts.intersect(cmort, temp, temp2, trend, part, part_lag4, dframe = TRUE)
fit = lm(cmort~ trend + temp + temp2 + part + part_lag4, data = data_set, na.action=NULL)
summary(fit)
library('astsa')
##2.2
# Add P(t-4) to regression
temp  = tempr-mean(tempr)  # center temperature
temp2 = temp^2             # square it
trend = time(cmort)        # time
part_lag4 = lag(part, 44)
data_set = ts.intersect(cmort, temp, temp2, trend, part, part_lag4)
fit = lm(cmort~ trend + temp + temp2 + part + part_lag4, data = data_set, na.action=NULL)
summary(fit)
ar = arima.sim(list(order=c(1,0,0), ar=.6), n=100)
ma = arima.sim(list(order=c(0,0,1), ma=.9), n=100)
arma = arima.sim(list(order=c(1,0,1), ar=.6, ma=.9), n=100) par(mfcol=c(1,2))
acf(ar)
pacf(ar)
par(mfcol=c(1,2))
acf(ma)
pacf(ma)
par(mfcol=c(1,2))
acf(arma)
pacf(arma)
ar = arima.sim(list(order=c(1,0,0), ar=.6), n=100)
ma = arima.sim(list(order=c(0,0,1), ma=.9), n=100)
arma = arima.sim(list(order=c(1,0,1), ar=.6, ma=.9), n=100)
par(mfcol=c(1,2))
acf(ar)
pacf(ar)
par(mfcol=c(1,2))
acf(ma)
pacf(ma)
par(mfcol=c(1,2))
acf(arma)
pacf(arma)
install.packages('car')
data = read.csv('step1_data.csv')
library(car)
data = read.csv('step1_data.csv')
3.1*100.65%
3.1*100.65、100
3.1*100.65/100
3.09*100.65/100
3.09*101/100
3.09*102/100
93.13-91.76
1.37/93.13
5.2-5.01
0.19/5
0.19/5.2
library(sparklyr)
install.packages('sparklyr')
library(sparklyr)
sc <- spark_connect(master = "local")
spark_install()
sc <- spark_connect(master = "local")
library(dplyr)
iris_tbl <- copy_to(sc, iris)
iris_tbl
spark_apply(iris_tbl, function(data) {
data[1:4] + rgamma(1,2)
})
library(sparklyr)
sc <- spark_connect(master = "local")
library(dplyr)
iris_tbl <- copy_to(sc, iris)
iris_tbl
spark_apply(iris_tbl, function(data) {
data[1:4] + rgamma(1,2)
})
spark_apply(
iris_tbl,
function(e) broom::tidy(lm(Petal_Width ~ Petal_Length, e)),
names = c("term", "estimate", "std.error", "statistic", "p.value"),
group_by = "Species"
)
library(ggplot2)
library(ggmap)
register_google(key = "[AIzaSyCl8BVE2jB-EAUtzvjrUonBoKm-Rz8VdBg]")
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
Sys.setenv(http_proxy="http://KEM.SG7.SSR.LC:10173")
library(ggplot2)
library(ggmap)
register_google(key = "[AIzaSyCl8BVE2jB-EAUtzvjrUonBoKm-Rz8VdBg]")
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
Sys.getenv("http_proxy")
Sys.getenv("http_proxy_user")
Sys.getenv("https_proxy")
Sys.setenv(http_proxy="http://KEM.SG7.SSR.LC:10173")
library(ggplot2)
library(ggmap)
register_google(key = "[AIzaSyCl8BVE2jB-EAUtzvjrUonBoKm-Rz8VdBg]")
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
a=ggmap(north_ca) +
geom_point(data=quakes, aes(x=long, y=lat, colour=depth), alpha=0.8) +
labs(x="", y="") +
scale_colour_gradient(low="#0080FF", high="tomato")+
labs(x = "Longitude", y = "Latitude")+
ggtitle("Earthquakes in Northern California 2008 - 2011 YangJichen")
setwd('/Users/yangjichen/Desktop/课程/数据可视化/HW3')
ggsave('problem4a.jpg', a)
################################
Sys.setenv(http_proxy="http://KEM.SG7.SSR.LC:10173")
library(ggplot2)
library(ggmap)
register_google(key = "[AIzaSyCl8BVE2jB-EAUtzvjrUonBoKm-Rz8VdBg]")
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
Sys.setenv(http_proxy="http://KEM.SG7.SSR.LC:10173")
library(ggplot2)
library(ggmap)
register_google(key = "[AIzaSyCl8BVE2jB-EAUtzvjrUonBoKm-Rz8VdBg]")
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
Sys.setenv(http_proxy="sf1.kingss.me:22722")
library(ggplot2)
library(ggmap)
register_google(key = "[AIzaSyCl8BVE2jB-EAUtzvjrUonBoKm-Rz8VdBg]")
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
register_google(key = "AIzaSyCl8BVE2jB-EAUtzvjrUonBoKm-Rz8VdBg")
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
register_google(key = "AIzaSyCl8BVE2jB-EAUtzvjrUonBoKm-Rz8VdBg")
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
library(ggplot2)
library(ggmap)
register_google(key = "AIzaSyCl8BVE2jB-EAUtzvjrUonBoKm-Rz8VdBg")
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
library(ggplot2)
library(ggmap)
register_google(key = "AIzaSyCl8BVE2jB-EAUtzvjrUonBoKm-Rz8VdBg")
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
register_google(key = "[AIzaSyCl8BVE2jB-EAUtzvjrUonBoKm-Rz8VdBg]")
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
register_google(key = "AIzaSyCl8BVE2jB-EAUtzvjrUonBoKm-Rz8VdBg")
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
library(ggplot2)
library(ggmap)
register_google(key = "AIzaSyCl8BVE2jB-EAUtzvjrUonBoKm-Rz8VdBg")
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
showing_key()
ggmap_show_api_key()
google_key()
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
register_google(key = "AIzaSyCl8BVE2jB-EAUtzvjrUonBoKm-Rz8VdBg")
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
ggmap_show_api_key()
register_google(key = "AIzaSyCl8BVE2jB-EAUtzvjrUonBoKm-Rz8VdBg")
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
?get_googlemap
#point
north_ca = get_googlemap(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
quakes
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
R.home()
get_map
library(httr)
set_config(use_proxy(url="127.0.0.1",port=1080))
library(ggplot2)
library(ggmap)
register_google(key = "AIzaSyCl8BVE2jB-EAUtzvjrUonBoKm-Rz8VdBg")
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
set_config(use_proxy(url="127.0.0.1",port=8090))
library(ggplot2)
library(ggmap)
register_google(key = "AIzaSyCl8BVE2jB-EAUtzvjrUonBoKm-Rz8VdBg")
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
set_config(use_proxy(url="127.0.0.1",port=8090))
library(ggplot2)
library(ggmap)
register_google(key = "AIzaSyCl8BVE2jB-EAUtzvjrUonBoKm-Rz8VdBg")
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
library(httr)
set_config(use_proxy(url="127.0.0.1",port=1087))
library(ggplot2)
library(ggmap)
register_google(key = "AIzaSyCl8BVE2jB-EAUtzvjrUonBoKm-Rz8VdBg")
#point
north_ca = get_map(location = c(lon=mean(quakes$long), lat=mean(quakes$lat)),
maptype="terrain", zoom=4)
a=ggmap(north_ca) +
geom_point(data=quakes, aes(x=long, y=lat, colour=depth), alpha=0.8) +
labs(x="", y="") +
scale_colour_gradient(low="#0080FF", high="tomato")+
labs(x = "Longitude", y = "Latitude")+
ggtitle("Earthquakes in Northern California 2008 - 2011 YangJichen")
a
data(baseball, package="plyr")
baseball %>%
group_by(id) %>%
summarise(
seasons = max(year)-min(year)+1, atbats = sum(ab),
avg = sum(h, na.rm=T)/sum(ab, na.rm=T)
)
baseball %.%
group_by(id) %.%
summarise(
seasons = max(year)-min(year)+1, atbats = sum(ab),
avg = sum(h, na.rm=T)/sum(ab, na.rm=T)
)
data(baseball, package="plyr")
baseball %>%
group_by(id) %>%
summarise(
seasons = max(year)-min(year)+1, atbats = sum(ab),
avg = sum(h, na.rm=T)/sum(ab, na.rm=T)
)
library('sparklyr')
sc = spark_connect(master = 'local')
library('dplyr')
head('iris')
iris_tbl <- sdf_copy_to(sc = sc, x = iris, overwrite = T)
sc = spark_connect(master = 'local')
sc = spark_connect(master = 'local')
library('dplyr')
head('iris')
iris_tbl <- sdf_copy_to(sc = sc, x = iris, overwrite = T)
library('sparklyr')
library('dplyr')
sc = spark_connect(master = 'local')
iris_tbl <- sdf_copy_to(sc = sc, x = iris, overwrite = T)
data(baseball, package="plyr")
baseball %>%
group_by(id) %>%
summarise(
seasons = max(year)-min(year)+1, atbats = sum(ab),
avg = sum(h, na.rm=T)/sum(ab, na.rm=T)
)
library(dplyr)
library(sparklyr)
library(ggplot2)
baseball = plyr::baseball
sc <- spark_connect(master = "local")
baseball_tbl = copy_to(sc, baseball)
library(dplyr)
library(sparklyr)
library(ggplot2)
baseball = plyr::baseball
sc <- spark_connect(master = "local")
data(baseball, package="plyr")
baseball_tbl %>%
group_by(id) %>%
summarise(
seasons = max(year)-min(year)+1, atbats = sum(ab),
avg = sum(h, na.rm=T)/sum(ab, na.rm=T)
)
baseball_tbl = copy_to(sc, baseball)
baseball_tbl %>%
group_by(id) %>%
summarise(
seasons = max(year)-min(year)+1, atbats = sum(ab),
avg = sum(h, na.rm=T)/sum(ab, na.rm=T)
)
baseball_tbl
library('ggplot2')
library(dplyr)
library(sparklyr)
sc <- spark_connect(master = "local")
diamonds_tbl = copy_to(sc, diamonds)
help(diamonds)
summary(diamonds)
model_tbl = diamonds_tbl %>%
filter(!is.na(price)&!is.na(carat)&!is.na(cut)&!is.na(color)&!is.na(clarity)) %>%
mutate(price_rank = as.numeric(price > 5324),
log_price = log10(price),
new_carat = carat^(1/3))
library(gss)
?gssanova
e^12.4
exp(12.4/100*5)
typee = 'negBinomial'
sizee = '/size50'
library(ggplot2)
library(stringr)
setwd(paste('/Users/yangjichen/Desktop/project/Pub_opi_tensor/exponential\ family\ tensor/code/',typee,sizee,sep = ''))
file_names<- list.files(paste('/Users/yangjichen/Desktop/project/Pub_opi_tensor/exponential\ family\ tensor/code/',typee,sizee,sep = ''))
#先把所有结果读入，并将tsvd转置，variable变量是指所有的数据集名字
#注意assign和get函数的使用
variable = c()
for (i in 1:length(file_names)) {
if(grepl("result.csv", file_names[i])){
name<-gsub(".csv","",file_names[i])
variable = append(variable,name)
assign(name,read.csv(file_names[i],header = FALSE))
}
}
#这里整理数据集成需要的形式
resultdf = data.frame()
for (i in 1:length(variable)){
df = get(variable[i])
MR = seq(0.05,0.85,0.1)
median = apply(df,2,median)
method = rep(variable[i],9)
upper = apply(df,2,quantile,probs =0.75 )
lower = apply(df,2,quantile,probs =0.25 )
newdf <- data.frame(
MR = factor(MR),#MR
median = median, #mean
method = factor(method), #methods
upper =upper, #upper
lower = lower #lower
)
resultdf = rbind(resultdf,newdf)
}
p <- ggplot(resultdf, aes(MR,median, colour = method))
p +
geom_line(aes(group = method),size = 1) +
geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2)
ggsave(paste(typee,".png",sep = ''))
